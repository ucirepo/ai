{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9be8cf17-8f13-4808-a551-4673c132a631",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The optimal value is:10\n"
     ]
    }
   ],
   "source": [
    "#min-max\n",
    "import math \n",
    "import sys\n",
    "sys.setrecursionlimit(10000)\n",
    "\n",
    "def minimax(curDepth, nodeIndex, maxTurn, scores, targetDepth) : \n",
    "    if curDepth == targetDepth:\n",
    "        return scores[nodeIndex]\n",
    "\n",
    "    if maxTurn:\n",
    "        return max(minimax(curDepth + 1, nodeIndex * 2, False, scores, targetDepth),\n",
    "            minimax(curDepth + 1, nodeIndex * 2 + 1, False, scores, targetDepth))\n",
    "    else:\n",
    "        return min(minimax(curDepth + 1, nodeIndex * 2, True, scores, targetDepth), \n",
    "                   minimax(curDepth + 1, nodeIndex * 2 + 1, True, scores, targetDepth))\n",
    "\n",
    "\n",
    "scores = [10, 9, 14, 18, 5, 4, 50, 3]\n",
    "treeDepth = int(math.log(len(scores), 2))\n",
    "\n",
    "print('The optimal value is:', end='') \n",
    "print(minimax(0, 0, True, scores, treeDepth))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "908ca11e-94f1-44a9-8245-5859ce8bbeb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The optimal value is :  10\n"
     ]
    }
   ],
   "source": [
    "#alpha beta pruning :\n",
    "MAX , MIN =1000 , -1000\n",
    "\n",
    "def minimax(depth , nodeIndex , maximizingPlayer , values , alpha , beta):\n",
    "  if depth == 3:\n",
    "    return values[nodeIndex]\n",
    "  if maximizingPlayer:\n",
    "    best = MIN\n",
    "    for i in range(0,2):\n",
    "      val = minimax(depth + 1 , nodeIndex * 2 + i , False , values , alpha , beta)\n",
    "      best = max(best , val)\n",
    "      alpha = max(alpha , best)\n",
    "      if beta <= alpha:\n",
    "        break\n",
    "    return best\n",
    "  else:\n",
    "    best = MAX\n",
    "    for i in range(0,2):\n",
    "      val = minimax(depth + 1 , nodeIndex * 2 + i , True , values , alpha , beta)\n",
    "      best = min(best , val)\n",
    "      beta = min(beta , best)\n",
    "      if beta <= alpha:\n",
    "        break\n",
    "    return best   \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "  values = [10,9,14,18,5,4,50,3]\n",
    "  print(\"The optimal value is : \",minimax(0 , 0 , True , values , MIN , MAX))\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ccfde975-d059-4487-a28f-0a3fa82e610f",
   "metadata": {},
   "source": [
    "AI can be defined as a program that makes decisions and takes action based on decisions"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d9fb2456-e593-40a5-99c4-95e4e4d9c6c4",
   "metadata": {},
   "source": [
    "An agent can be anything that perceive its environment through sensors and act upon that environment through actuators (Effectors). An Agent runs in the cycle of perceiving, thinking, and acting."
   ]
  },
  {
   "cell_type": "raw",
   "id": "c7878af2-ca40-4736-9f8a-a0b40d7a1707",
   "metadata": {},
   "source": [
    "PEAS\n",
    "1) Performance - Safety, time, comfort\n",
    "        Metrics to determine optimal conditions\n",
    "2) Environment - Roads, pedestrian, signs\n",
    "        Surroundings and relative objects\n",
    "3) Actuators - Steering, accelerator, brake\n",
    "        Things that determine an action\n",
    "4) Sensors - Camera, gps, speedometer\n",
    "        Things that sense stuff"
   ]
  },
  {
   "cell_type": "raw",
   "id": "bbc2b62a-965e-4adb-a9d6-054078062b13",
   "metadata": {},
   "source": [
    "Types of AI agents:-\n",
    "\n",
    "1) Simple Reflex Agent - These take decisions on the basis of the current percepts and ignore the rest of the percept history.\n",
    "\n",
    "Agent\n",
    "                                        Sensors<------Percepts------- Environment\n",
    "                                            |\n",
    "                            What the world is like now\n",
    "                                            |\n",
    "        Condition-Action Rules -----> What action I should do now\n",
    "                                            |\n",
    "                                        Actuators------Action-------->Environment"
   ]
  },
  {
   "cell_type": "raw",
   "id": "658bf764-a944-4f98-ae13-90a4933ad64d",
   "metadata": {},
   "source": [
    "2) Model based reflex agent - Can work in a partially observable environment and track the situation\n",
    "\n",
    "Agent\n",
    "                                                        Sensors<------Percepts------- Environment\n",
    "                                                            |\n",
    "State, How the world evolves, What my actions do----> What the world is like now\n",
    "                                                            |\n",
    "                        Condition-Action Rules -----> What action I should do now\n",
    "                                                            |\n",
    "                                                        Actuators------Action-------->Environment"
   ]
  },
  {
   "cell_type": "raw",
   "id": "da5c9b6c-20e9-476e-9a9a-46e5c37b10dd",
   "metadata": {},
   "source": [
    "3) Goal based agents - Takes actions based on goal.\n",
    "\n",
    "Agent\n",
    "                                                        Sensors<------Percepts------- Environment\n",
    "                                                            |\n",
    "State, How the world evolves, What my actions do----> What the world is like now\n",
    "                                                            |\n",
    "    How the world evolves, What my actions do ----->  What will it be like if i do action A\n",
    "                                                            |\n",
    "                        Condition-Action Rules -----> What action I should do now\n",
    "                                                            |\n",
    "                                                        Actuators------Action-------->Environment"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b3b278e0-dc22-457b-83d8-6af6df28ffaf",
   "metadata": {},
   "source": [
    "4) Utility based agenta - similar to the goal-based agent but provide an extra component of utility measurement which makes them different by providing a measure of success at a given state. Acts based on best way to achieve the goals\n",
    "\n",
    "Agent\n",
    "                                                        Sensors<------Percepts------- Environment\n",
    "                                                            |\n",
    "State, How the world evolves, What my actions do----> What the world is like now\n",
    "                                                            |\n",
    "    How the world evolves, What my actions do ----->  What will it be like if i do action A\n",
    "                                                            |\n",
    "                                      Utility ------> How happy will I be in such a state\n",
    "                                                            |\n",
    "                        Condition-Action Rules -----> What action I should do now\n",
    "                                                            |\n",
    "                                                        Actuators------Action-------->Environment"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ce813a46-8ac2-4217-9b02-55be72fa0881",
   "metadata": {},
   "source": [
    "5) Learning Agents - Has learning capabilities, learns from past experiences. starts with basic and adapts\n",
    "\n",
    "Agent\n",
    "    Performance Standard\n",
    "            |\n",
    "        Critics<------------------------------------------Sensors<------Percepts------ Environment\n",
    "  feedback  |                                                 |\n",
    "    Learning Element<----Changes-----/-----Knowledge----->Performance Element\n",
    "Learning goals|\n",
    "    Problem Generator-----------Experiments--------->\"\n",
    "                                                            |\n",
    "                                                        Effectors--------Actions------->Environment"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
